---
title: "taller4"
output: html_document
date: '2022-03-11'
---

Un investigador bla bla bla ... 

**A) con $\alpha = 0.05$, haga una prueba de hipótesis con el $T^{2}$ sobre si todas las medias son las mismas.**

Primero definimos las variables:

```{r}
x_bar = rbind(46.1, 57.3, 50.4)
S = matrix(c(101.3, 63.0, 71.0, 63.0, 80.2, 55.6, 71.0, 55.6, 97.4),
           nrow = 3, ncol = 3)

C = matrix(c(1, 1, -1, 0, 0,-1),
           nrow = 2, ncol = 3)
N = 40
```

*Una función para multiples usos:*

```{r setup, include=TRUE}

hypo_test_mean_comparisson_tsquared <- function(xbar, s, c, alpha, n){
  
  # xbar -> vector columna de las medias
  # s -> matriz de covarianzas y varianzas
  # c -> matriz de contraste
  # n -> numero de muestras


  q = dim(xbar)[1]
  alpha = 0.05
  
  t_squared = n* t(c %*% xbar) %*% solve(c%*% s %*% t(c)) %*%(c %*% xbar) 
  t_alpha = qf(p = 1-alpha, df1 = q-1 , df2 = n-q+1) * ((n-1)*(q-1)/(n-q+1))

  #print("¿Se rechaza la hipótesis nula?")
  #print( (t_squared > t_alpha)[1] )
  
  return( data.frame(t_squared, t_alpha) )
}

```

*Los resultados son:*

```{r}
ans = hypo_test_mean_comparisson_tsquared(xbar = x_bar, 
                           s = S, 
                           c = C, 
                           alpha = 0.05,
                           n = N)

ans
```


B) Juzgue las diferencias de los pares de medias de los índices usando intervalos de confianza $T^{2}$ simultáneos del 95%.

```{r}

hypo_test_mean_comparisson_by_intervals <- function(xbar, s, c, alpha, n){

  # xbar -> vector columna de las medias
  # s -> matriz de covarianzas y varianzas
  # c -> matriz de contraste
  # n -> numero de muestras

  q = dim(xbar)[1]
  alpha = 0.05
  
  delta_means = c%*%xbar
  t_alpha = qf(p = 1-alpha, df1 = q-1 , df2 = n-q+1) * ((n-1)*(q-1)/(n-q+1))
  var_mat = c%*% s %*% t(c)
  
  #inf = delta_means %+% sqrt(t_alpha) %*% sqrt(var_mat/n)
  #sup = delta_means %-% sqrt(t_alpha) %*% sqrt(var_mat/n)
  
  #print(inf)
  #print(sup)
  return ()
}

```

```{r}
hypo_test_mean_comparisson_by_intervals(xbar = x_bar,
                                        s = S, 
                                        c = C,
                                        alpha = alpha,
                                        n = N)

```

### **2. Observaciones sobre dos respuestas ... **


### **3. Dados los datos**
**A) Ajuste el modelo de regresión lineal**

```{r}


linear_fit <- function(z, y){

  # Dado:
  # z: matriz de datos (donde las columnas representan
  #    cada variable de la cual se tienen mediciones)
  # y: vector columna
  
  # Retorna:
  # betas: vector columna de los betas
  
  # calcula el vector de betas
  betas = solve(t(z)%*%z) %*% t(z) %*% y
 
  return(betas) 
}

get_error <- function(betas, z, y){
  
  # Dado:
  # betas: vector con los pesos de las variables regresoras
  # z: matriz de datos (donde cada columna representa una variable)
  # y: vector columna del output medido
  #
  
  # Retorna:
  # La suma de residuos cuadrados (para el error), 
  # esto es: el error producto punto con él mismo.
  
  error = y - (z%*%betas)
  residual_sum_of_squares = t(error) %*% error
  
  return (residual_sum_of_squares[1])
}

```

```{r}

#datos originales
z1 = rbind(10, 5, 7, 19, 11, 18)
z2 = rbind(2, 3, 3, 6, 7, 9)

# columna de unos para obtener los betas
ndatapoints = dim(z1)[1]
ones = rbind(matrix(1, ndatapoints, 1))
  
# matriz de datos con la fila de unos
# añadida
z = cbind(ones, z1, z2)

#vector columna (output de los parametros)
y = rbind(15, 9, 3, 25, 7, 13)

betas = linear_fit(z, y)
betas
```
**B) Determine los intervalos de confianza del 95% simultaneos (uno a la vez), para $\beta_{1}, \beta_{2}$.**

```{r}


get_interval_for_betas <- function(z, y, betas, alpha){
  
  # dados:
  # z: matriz (donde cada columna es una variable distinta)
  # y: vector columna de los outputs
  # betas: vector columna de los betas (tantos como numeros de variables + beta_0)
  # alpha: 0.05, 0.01 (valor de confianza)
  
  # retorna:
  # total: dataframe de 2 columnas "inf", "sup" que indican el valor inferior
  # y otro que indica el valor superior del intervalo, por cada fila 
  # desde beta_0 hasta beta_n.
  
  #obtiene el número de variables
  nvars = dim(z)[2]
  
  #obtiene el numero de datos
  ndata = dim(z)[1]
  
  #dataframe donde se guardan las cotas superiores e inferiores
  total <- data.frame()
  
  ratio = sqrt( (nvars + 1)* qf(1-alpha, nvars+1, ndata-nvars-1)  )
  
  residual_sum_of_squares = get_error(betas, z, y)
  s_squared = residual_sum_of_squares/(ndata - nvars -1)
  z_squared_inv = solve(t(z)%*%z)
  
  for (i in seq(1, nvars, by=1)){
    sup = betas[i] + sqrt(z_squared_inv[i,i])*ratio
    inf = betas[i] - sqrt(z_squared_inv[i,i])*ratio
    
    total <- rbind(total, data.frame(inf, sup))
  }
  
  return (total)
}

intervals = get_interval_for_betas(z, y, betas, 0.05)
intervals
```

**C) Comprueba la prueba de hipótesis nula de que sólo el coeficiente $\beta_{1}$ es cero**

Dado que el valor de cero no se encuentra en los intervalos creados con 95% de confianza para $\beta_{1}$, concluimos de que esa hipótesis nula es falsa. 

Sin embargo para hacer la prueba de hipótesis completa:

```{r}

hipo_test_betas_values <- function(z, y, c, betas, alpha){
  
  # Dados:
  # z: matriz de datos donde cada columna representa una variable distinta
  # y: vector columna de las output
  # c: vector de unos y ceros, se usa para crear los betas de la hipótesis
  #    nula, un cero va en la entrada correspondiente al beta que se quiere
  #    tomar como cero en la hipótesis nula (vector columna).
  # betas: maximum likelihood estimator para los betas (vector columna)
  # alpha: nivel de confianza
  
  # Retorna:
  # retorna el valor del estadistico de prueba y del valor limite de rechazo
  
  ndata = dim(z)[1]
  nvars = dim(z)[2]
  #numero de variables que son cero según la hipótesis nula
  nnullvars = nvars - sum(c)
  
  #multiplica entrada a entrada los betas con el vector columna c
  betas0 = betas * c
  
  # sum of squares of deviations, entre lo observado 
  # y lo calculado para la hipotesis nula
  sse0 = get_error(betas0, z, y)
  
  # sum of squares of deviations, entre lo observado 
  # y lo calculado para la hipotesis alternativa
  sseA = get_error(betas, z, y)

  s_squared = sseA/(ndata - nvars -1)
  test_statistic = ((sse0 - sseA)/(nnullvars))/s_squared
  
  rejection_value = qf(p = 1-alpha, df1 = nnullvars, df2 =ndata - nvars -1)
  
  return (data.frame(test_statistic, rejection_value))
}

```

Dado que el valor del estadístico de prueba es muchísimo mayor que el valor de rechazo entonces tenemos que por prueba de hipótesis también se llega a que $\beta_{1} \neq 0$.


```{r}

# prueba de hipótesis para decir que b1 = 0
c = rbind(1, 0, 1)
hipo_test_betas_values(z, y, c, betas, alpha = 0.05)
```










